{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-X Spring 2019: Homework 06 \n",
    "\n",
    "## Name : Benedict Ng\n",
    "## SID : 3034453726\n",
    "## Course (IEOR 135/290) : 135\n",
    "\n",
    "### Machine Learning\n",
    "\n",
    "\n",
    "\n",
    "In this homework, you will do some exercises with prediction. We will cover these algorithms in class, but this is for you to have some hands on with these in scikit-learn. You can refer - https://github.com/ikhlaqsidhu/data-x/blob/master/05a-tools-predicition-titanic/titanic.ipynb\n",
    "\n",
    "Display all your outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # machine learning libraries\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "__ 1. Read __`diabetesdata.csv`__ file into a pandas dataframe. \n",
    "About the data: __\n",
    "\n",
    "1. __TimesPregnant__: Number of times pregnant \n",
    "2. __glucoseLevel__: Plasma glucose concentration a 2 hours in an oral glucose tolerance test \n",
    "3. __BP__: Diastolic blood pressure (mm Hg)  \n",
    "5. __insulin__: 2-Hour serum insulin (mu U/ml) \n",
    "6. __BMI__: Body mass index (weight in kg/(height in m)^2) \n",
    "7. __pedigree__: Diabetes pedigree function \n",
    "8. __Age__: Age (years) \n",
    "9. __IsDiabetic__: 0 if not diabetic or 1 if diabetic) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimesPregnant</th>\n",
       "      <th>glucoseLevel</th>\n",
       "      <th>BP</th>\n",
       "      <th>insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Pedigree</th>\n",
       "      <th>Age</th>\n",
       "      <th>IsDiabetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TimesPregnant  glucoseLevel  BP  insulin   BMI  Pedigree   Age  IsDiabetic\n",
       "0              6         148.0  72        0  33.6     0.627  50.0           1\n",
       "1              1           NaN  66        0  26.6     0.351  31.0           0\n",
       "2              8         183.0  64        0  23.3     0.672   NaN           1\n",
       "3              1           NaN  66       94  28.1     0.167  21.0           0\n",
       "4              0         137.0  40      168  43.1     2.288  33.0           1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read data & print the head\n",
    "df = pd.read_csv(\"diabetesdata.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Calculate the percentage of Null values in each column and display it. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimesPregnant    0.000000\n",
       "glucoseLevel     4.427083\n",
       "BP               0.000000\n",
       "insulin          0.000000\n",
       "BMI              0.000000\n",
       "Pedigree         0.000000\n",
       "Age              4.296875\n",
       "IsDiabetic       0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_missing= df.isnull().sum()/len(df)*100\n",
    "percent_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Split __`data`__  into  __`train_df`__ and __`test_df`__  with 15% as test.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(652, 8)\n",
      "(116, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df, test_size=0.15)\n",
    "print (train.shape)\n",
    "print (test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Display the means of the features in train and test sets. Replace the null values in  __`train_df`__ and __`test_df`__  with the mean of EACH feature column separately for train and test. Display head of the dataframes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimesPregnant      3.823620\n",
      "glucoseLevel     121.739903\n",
      "BP                69.734663\n",
      "insulin           81.288344\n",
      "BMI               32.059202\n",
      "Pedigree           0.466299\n",
      "Age               33.241600\n",
      "IsDiabetic         0.360429\n",
      "dtype: float64\n",
      "TimesPregnant      3.965517\n",
      "glucoseLevel     117.121739\n",
      "BP                65.568966\n",
      "insulin           71.431034\n",
      "BMI               31.618103\n",
      "Pedigree           0.503224\n",
      "Age               33.990909\n",
      "IsDiabetic         0.284483\n",
      "dtype: float64\n",
      "     TimesPregnant  glucoseLevel  BP  insulin   BMI  Pedigree   Age  \\\n",
      "257              2         114.0  68        0  28.7     0.092  25.0   \n",
      "582             12         121.0  78        0  26.5     0.259  62.0   \n",
      "394              4         158.0  78        0  32.9     0.803  31.0   \n",
      "156              2          99.0  52       94  24.6     0.637  21.0   \n",
      "176              6          85.0  78        0  31.2     0.382  42.0   \n",
      "\n",
      "     IsDiabetic  \n",
      "257           0  \n",
      "582           0  \n",
      "394           1  \n",
      "156           0  \n",
      "176           0  \n",
      "     TimesPregnant  glucoseLevel  BP  insulin   BMI  Pedigree   Age  \\\n",
      "473              7         136.0  90        0  29.9     0.210  50.0   \n",
      "346              1         139.0  46       83  28.7     0.654  22.0   \n",
      "632              2         111.0  60        0  26.2     0.343  23.0   \n",
      "390              1         100.0  66      196  32.0     0.444  42.0   \n",
      "743              9         140.0  94        0  32.7     0.734  45.0   \n",
      "\n",
      "     IsDiabetic  \n",
      "473           0  \n",
      "346           0  \n",
      "632           0  \n",
      "390           0  \n",
      "743           1  \n"
     ]
    }
   ],
   "source": [
    "train_mean = train.mean(skipna=True)\n",
    "test_mean = test.mean(skipna=True)\n",
    "train = train.fillna(train_mean)\n",
    "test = test.fillna(test_mean)\n",
    "print (train_mean)\n",
    "print (test_mean)\n",
    "print (train.head())\n",
    "print (test.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Split __`train_df`__ & __`test_df`__   into  __`X_train`__, __`Y_train`__  and __`X_test`__, __`Y_test`__. __`Y_train`__  and __`Y_test`__ should only have the column we are trying to predict,  __`IsDiabetic`__.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = train.drop('IsDiabetic',axis = 1)\n",
    "Y_train = train['IsDiabetic']\n",
    "X_test = test.drop('IsDiabetic',axis = 1)\n",
    "Y_test = test['IsDiabetic']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Use this dataset to train perceptron, logistic regression and random forest models using 15% test split. Report training and test accuracies. Try different hyperparameter values for these models and see if you can improve your accuracies.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.769938650307\n",
      "Test Accuracy: 0.801724137931\n",
      "Confusion Matrix\n",
      "[[73 10]\n",
      " [13 20]]\n",
      "Precision: [ 0.84883721  0.66666667]\n",
      "Recall: [ 0.87951807  0.60606061]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "logreg = linear_model.LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "print(\"Training Accuracy:\",metrics.accuracy_score(Y_train, logreg.predict(X_train)))\n",
    "print(\"Test Accuracy:\",metrics.accuracy_score(Y_test, logreg.predict(X_test)))\n",
    "cnf_matrix = metrics.confusion_matrix(Y_test, logreg.predict(X_test))\n",
    "print ('Confusion Matrix')\n",
    "print (cnf_matrix)\n",
    "print(\"Precision:\",metrics.precision_score(Y_test, logreg.predict(X_test), average = None))\n",
    "print(\"Recall:\",metrics.recall_score(Y_test, logreg.predict(X_test), average = None))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.650306748466\n",
      "Test Accuracy: 0.663793103448\n"
     ]
    }
   ],
   "source": [
    "# 6b. Perceptron\n",
    "ppn = Perceptron(n_iter=40, eta0=0.1, random_state=0)\n",
    "ppn.fit(X_train, Y_train)\n",
    "print(\"Training Accuracy:\",metrics.accuracy_score(Y_train, ppn.predict(X_train)))\n",
    "print(\"Test Accuracy:\",metrics.accuracy_score(Y_test, ppn.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.760736196319\n",
      "Test Accuracy: 0.836206896552\n"
     ]
    }
   ],
   "source": [
    "#### 6c. Random Forest\n",
    "rfor = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "rfor.fit(X_train, Y_train)\n",
    "print(\"Training Accuracy:\",metrics.accuracy_score(Y_train, rfor.predict(X_train)))\n",
    "print(\"Test Accuracy:\",metrics.accuracy_score(Y_test, rfor.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. For your logistic regression model - **\n",
    "\n",
    "**a . Compute the log probability of classes in  __`IsDiabetic`__ for the first 10 samples of your train set and display it. Also display the predicted class for those samples from your logistic regression model trained before. **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log probability: [[-0.19135965 -1.74775514]\n",
      " [-0.64384482 -0.74500689]\n",
      " [-0.88574326 -0.53172165]\n",
      " [-0.1917893  -1.74572038]\n",
      " [-0.19856445 -1.71428147]\n",
      " [-0.2455891  -1.52437819]\n",
      " [-0.42150453 -1.0672852 ]\n",
      " [-0.06958102 -2.69985219]\n",
      " [-0.44524313 -1.0235099 ]\n",
      " [-0.7959677  -0.59991998]]\n",
      "predicted class: [0 0 1 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print (\"log probability:\",logreg.predict_log_proba(X_train.head(10)))\n",
    "print (\"predicted class:\", logreg.predict(X_train.head(10)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b . Now compute the log probability of classes in  __`IsDiabetic`__ for the first 10 samples of your test set and display it. Also display the predicted class for those samples from your logistic regression model trained before.\n",
    " (using the model trained on the training set)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log probability: [[-0.48187683 -0.96134859]\n",
      " [-0.57449505 -0.8277971 ]\n",
      " [-0.20536647 -1.68388579]\n",
      " [-0.22712566 -1.5936662 ]\n",
      " [-0.80679493 -0.59110725]\n",
      " [-0.53650048 -0.87897367]\n",
      " [-0.82572398 -0.57610724]\n",
      " [-0.23919218 -1.54770131]\n",
      " [-0.55762959 -0.84995227]\n",
      " [-0.19822316 -1.71583676]]\n",
      "predicted class: [0 0 0 0 1 0 1 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print (\"log probability:\",logreg.predict_log_proba(X_test.head(10)))\n",
    "print (\"predicted class:\", logreg.predict(X_test.head(10)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c . What can you interpret from the log probabilities and the predicted classes?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more negative result will be the predicted class. The classifier will always choose the more probable prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Is mean imputation is the best type of imputation (as we did in 4.) to use? Why or why not? What are some other ways to impute the data?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with mean imputation is that it does not preserve the relationships among the variables.\n",
    "Mean imputation preserves the mean of the observed data. If the missing data is completely random, the estimate of the mean will remain unbiased. However this assumes that the relationship between the variables and the predicted value is strong which may not be the case. Hence the real relationship will be underestimated. \n",
    "\n",
    "Regression imputation can be used. This involves predicting the missing variable by performing a regression on the other variables that are present. Using the predicted value preserves the relationships among the variables, which mean imputation is unable to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit (2 pts) - MANDATORY for students enrolled in IEOR 290"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**9.  Implement the K-Nearest Neighbours (https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) algorithm for k=1 from scratch in python (do not use KNN from existing libraries). KNN uses Euclidean distance to find nearest neighbors. Split your dataset into test and train as before. Also fill in the null values with mean of features as done earlier. Use this algorithm to predict values for 'IsDiabetic' for your test set. Display your accuracy. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'distance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-8bca8d7befe7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mKNN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNearestNeighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mKNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mKNN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-8bca8d7befe7>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, to_predict, return_kneighbor_inds)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m          \u001b[1;31m#get distance input_data to predict\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mdists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_predict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[1;31m#get indices of k nearest points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'distance' is not defined"
     ]
    }
   ],
   "source": [
    "class KNearestNeighbors():\n",
    "    def __init__ (self, n_neighbors=1):\n",
    "        '''\n",
    "        n_neighbors: number of neighbors\n",
    "        '''\n",
    "        self.n_neighbors = n_neighbors\n",
    "    \n",
    "    def fit(self, input_data, response):\n",
    "        '''\n",
    "        input_data: a table, the values of this table will be used to \n",
    "            compute the distance to the neighbors\n",
    "        response: a table with one column, the values in this column \n",
    "            represent the category of the thing we are trying to predict \n",
    "        '''\n",
    "        self.input_data = input_data.values\n",
    "        self.response = response.values.flatten()\n",
    "    \n",
    "    def predict(self, to_predict, return_kneighbor_inds=True):\n",
    "        '''\n",
    "        to_predict: A single input data point. It should contain one value \n",
    "           for each of the columns in the input_data table.\n",
    "        return_kneighbor_inds: boolean. If True, return the indices of the\n",
    "            nearest neighbors from the input table, otherwise, only the \n",
    "            majority category of the k-nearest neighbors is returned.\n",
    "        '''\n",
    "        \n",
    "         #get distance input_data to predict\"\n",
    "        dists = distance(to_predict, self.input_data)\n",
    "\n",
    "        #get indices of k nearest points\n",
    "        inds = np.argsort(dists)[0:self.n_neighbors]\n",
    "\n",
    "        #return the most common response among the neighbors\n",
    "        most_common_response = (np.argmax(np.bincount(self.response[inds])))\n",
    "        if return_kneighbor_inds:\n",
    "            return most_common_response, inds\n",
    "        return most_common_response\n",
    "    \n",
    "KNN = KNearestNeighbors()\n",
    "KNN.fit(X_train, Y_train)\n",
    "KNN.predict(X_train)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "data-x"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "nteract": {
   "version": "0.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
